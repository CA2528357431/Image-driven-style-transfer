{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    " \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    " \n",
    "import copy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(device)\n",
    "imsize = 512\n",
    "\n",
    "loader = transforms.Compose([\n",
    "    transforms.Resize(imsize), #缩放小编为512\n",
    "    transforms.ToTensor()])\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    # h,w = image.size\n",
    "    image = loader(image).unsqueeze(0)\n",
    "\n",
    "    image = image.to(torch.float)\n",
    "\n",
    "    return image.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "unloader = transforms.ToPILImage()                                        # 重新转换为PIL图像\n",
    "\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def imshow(tensor):\n",
    "    image = tensor.cpu().clone()                                        # 我们克隆张量不对其进行更改\n",
    "    image = image.squeeze(0)                                            # 删除假批次尺寸\n",
    "    image = unloader(image)\n",
    "    plt.imshow(image)                                                # 稍停一下，以便更新地块\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 初始\n",
    "\n",
    "# plt.figure()\n",
    "# imshow(style_img)\n",
    "#\n",
    "# plt.figure()\n",
    "# imshow(content_img)\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 两个loss都是不改变经过他的数据，只更新自身loss\n",
    "\n",
    "class ContentLoss(nn.Module):\n",
    " \n",
    "    def __init__(self, target):\n",
    "        super().__init__()\n",
    " \n",
    "        # 我们将目标内容与所使用的树“分离”\n",
    "        # 动态计算梯度：这是一个规定值，\n",
    "        # 不是变量。 否则，准则的前进方法\n",
    "        # 将引发错误。\n",
    "        self.target = target.detach()\n",
    " \n",
    "    def forward(self, input):\n",
    "        self.loss = F.mse_loss(input, self.target)\n",
    "        return input\n",
    " \n",
    " \n",
    "def gram_matrix(input):\n",
    "    a, b, c, d = input.size()  # a=batch size(=1)\n",
    "    # b=特征图数量\n",
    "    # (c,d)=dimensions of a f. map (N=c*d)\n",
    " \n",
    "    features = input.view(a * b, c * d)  # 将FXML调整为\\ hat FXML\n",
    " \n",
    "    G = torch.mm(features, features.t())\n",
    " \n",
    "    # 我们将gram矩阵的值“规范化”\n",
    "    # 除以每个要素图中的元素数量。\n",
    "    return G/(a * b * c * d)\n",
    " \n",
    " \n",
    "class StyleLoss(nn.Module):\n",
    " \n",
    "    def __init__(self, target_feature):\n",
    "        super().__init__()\n",
    "        self.target = gram_matrix(target_feature).detach()\n",
    " \n",
    "    def forward(self, input):\n",
    "        G = gram_matrix(input)\n",
    "        self.loss = F.mse_loss(G, self.target)\n",
    "        return input\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 创建一个模块来标准化输入图像，以便我们可以轻松地将其放入\n",
    "# nn.Sequential\n",
    "class Normalization(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super().__init__()\n",
    "        # 查看均值和标准差以使其为[C x 1 x 1]，以便它们可以\n",
    "        # 直接使用形状为[B x C x H x W]的图像张量。\n",
    "        # B是批量大小。 C是通道数。 H是高度，W是宽度。\n",
    "\n",
    "        self.mean = mean.clone().detach().view(-1, 1, 1)\n",
    "        self.std = std.clone().detach().view(-1, 1, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        # normalize img\n",
    "        return (img - self.mean) / self.std\n",
    "\n",
    "\n",
    "# 所需的深度层以计算样式/内容损失：\n",
    "content_layers_default = ['conv_4']\n",
    "style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    " \n",
    "def get_style_model_and_losses(cnn, normalization_mean, normalization_std,\n",
    "                               style_img, content_img,\n",
    "                               content_layers=content_layers_default,\n",
    "                               style_layers=style_layers_default):\n",
    "    cnn = copy.deepcopy(cnn)\n",
    " \n",
    "    # 标准化模块\n",
    "    normalization = Normalization(normalization_mean, normalization_std).to(device)\n",
    "\n",
    "    # 只是为了获得对内容/样式的可迭代访问或列表\n",
    "    # losses\n",
    "    content_losses = []\n",
    "    style_losses = []\n",
    " \n",
    "    # 假设cnn是nn.Sequential，那么我们创建一个新的nn.Sequential\n",
    "    # 放入应该顺序激活的模块\n",
    "    model = nn.Sequential(normalization)\n",
    " \n",
    "    i = 0  # 每当转换时就增加\n",
    "    for layer in cnn.children():\n",
    "        name = \"\"\n",
    "        if isinstance(layer, nn.Conv2d):              #如果对象的类型与参数二的类型（classinfo）相同则返回 True，否则返回 False\n",
    "            i += 1\n",
    "            name = 'conv_{}'.format(i)\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            name = 'relu_{}'.format(i)\n",
    "            # 旧版本与我们在下面插入的ContentLoss和StyleLoss不能很好地配合使用。\n",
    "            # 因此，我们在这里替换为不适当的。\n",
    "            layer = nn.ReLU(inplace=False)\n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            name = 'pool_{}'.format(i)\n",
    "        elif isinstance(layer, nn.BatchNorm2d):\n",
    "            name = 'bn_{}'.format(i)\n",
    "\n",
    "        model.add_module(name, layer)\n",
    "\n",
    "        if name in content_layers:\n",
    "            # 增加内容损失:\n",
    "            target = model(content_img).detach()\n",
    "            content_loss = ContentLoss(target)\n",
    "            model.add_module(\"content_loss_{}\".format(i), content_loss)\n",
    "            content_losses.append(content_loss)\n",
    " \n",
    "        if name in style_layers:\n",
    "            # 增加样式损失:\n",
    "            target_feature = model(style_img).detach()\n",
    "            style_loss = StyleLoss(target_feature)\n",
    "            model.add_module(\"style_loss_{}\".format(i), style_loss)\n",
    "            style_losses.append(style_loss)\n",
    " \n",
    "    # 现在我们在最后一次内容和样式丢失后修剪图层\n",
    "    for i in range(len(model) - 1, -1, -1):\n",
    "        if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
    "            break\n",
    " \n",
    "    model = model[:(i + 1)]\n",
    " \n",
    "    return model, style_losses, content_losses\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    " \n",
    "def get_input_optimizer(input_img):\n",
    "    # 此行显示输入是需要渐变的参数\n",
    "    optimizer = optim.LBFGS([input_img.requires_grad_()])\n",
    "    return optimizer\n",
    " \n",
    " \n",
    "def run_style_transfer(cnn, normalization_mean, normalization_std,\n",
    "                       content_img, style_img, input_img, num_steps,\n",
    "                       style_weight, content_weight):\n",
    "    \"\"\"Run the style transfer.\"\"\"\n",
    "    print('Building the style transfer model..')\n",
    "    model, style_losses, content_losses = get_style_model_and_losses(cnn,\n",
    "                                                                     normalization_mean, normalization_std, style_img,\n",
    "                                                                     content_img)\n",
    "    optimizer = get_input_optimizer(input_img)\n",
    " \n",
    "    print('Optimizing..')\n",
    "    run = [0]\n",
    "    while run[0] <= num_steps:\n",
    " \n",
    "        def closure():\n",
    "            # 更正更新后的输入图像的值\n",
    "            input_img.data.clamp_(0, 1)\n",
    " \n",
    "            optimizer.zero_grad()\n",
    "            model(input_img)\n",
    "            style_score = 0\n",
    "            content_score = 0\n",
    " \n",
    "            for sl in style_losses:\n",
    "                style_score += sl.loss\n",
    "            for cl in content_losses:\n",
    "                content_score += cl.loss\n",
    " \n",
    "            style_score *= style_weight\n",
    "            content_score *= content_weight\n",
    " \n",
    "            loss = style_score + content_score\n",
    "            loss.backward()\n",
    " \n",
    "            run[0] += 1\n",
    "            if run[0] % 100 == 0:\n",
    "                print(\"run {}:\".format(run))\n",
    "                print('Style Loss : {:4f} Content Loss: {:4f}'.format(\n",
    "                    style_score.item(), content_score.item()))\n",
    "                print()\n",
    " \n",
    "            return style_score + content_score\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    input_img.data.clamp_(0,1)\n",
    "    return input_img\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def do(c,s,o):\n",
    "    style_img = image_loader(s)\n",
    "    content_img = image_loader(c)\n",
    "\n",
    "\n",
    "    input_img = content_img.clone()\n",
    "\n",
    "    cnn = models.vgg19(pretrained=True).features.to(device).eval()\n",
    "\n",
    "    cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
    "\n",
    "    cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
    "\n",
    "    output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std,\n",
    "                           content_img, style_img, input_img, num_steps=100,\n",
    "                           style_weight=20000, content_weight=1)\n",
    "\n",
    "    plt.figure()\n",
    "    # imshow(output)\n",
    "\n",
    "    saver = transforms.ToPILImage()\n",
    "\n",
    "    sav = saver(output[0].cpu().clone())\n",
    "\n",
    "    # sav = back2(sav)\n",
    "\n",
    "    sav.save(o)\n",
    "    # print(111)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the style transfer model..\n",
      "Optimizing..\n",
      "run [100]:\n",
      "Style Loss : 0.713924 Content Loss: 0.608284\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cb = \"./content/{}.jpg\"\n",
    "sb = \"./style/{}.jpg\"\n",
    "ob = \"./out/{}.jpg\"\n",
    "\n",
    "for i in range(1,2):\n",
    "    ci = i%7\n",
    "    si = i%7\n",
    "    c = cb.format(ci)\n",
    "    s = sb.format(si)\n",
    "    o = ob.format(i)\n",
    "    do(c,s,o)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}